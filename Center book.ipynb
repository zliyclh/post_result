{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from textwrap import wrap\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pyodbc \n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "country index mapping\n",
    "'''\n",
    "index_mapping={'AU':\"AS51 Index\",\n",
    "        \"AV\":\"SX5E Index\",\n",
    "        \"BB\":\"SX5E Index\",\n",
    "        \"CN\":\"SPX Index\",\n",
    "        \"CT\":\"SPX Index\",\n",
    "        \"DC\":\"SX5E Index\",\n",
    "        \"FH\":\"SX5E Index\",\n",
    "        \"FP\":\"SX5E Index\",\n",
    "        \"GY\":\"SX5E Index\",\n",
    "        \"HK\":\"HSI Index\",\n",
    "        \"ID\":\"SX5E Index\",\n",
    "        \"IM\":\"SX5E Index\",\n",
    "        \"JP\":\"TPX Index\",\n",
    "        \"JT\":\"TPX Index\",\n",
    "        \"KS\":\"KOSPI Index\",\n",
    "        \"LN\":\"SX5E Index\",\n",
    "        \"NA\":\"SX5E Index\",\n",
    "        \"NO\":\"SX5E Index\",\n",
    "        \"PL\":\"SX5E Index\",\n",
    "        \"SM\":\"SX5E Index\",\n",
    "        \"SQ\":\"SX5E Index\",\n",
    "        \"SS\":\"SX5E Index\",\n",
    "        \"SW\":\"SX5E Index\",\n",
    "        \"UN\":\"SPX Index\",\n",
    "        \"US\":\"SPX Index\",\n",
    "        \"VX\":\"SX5E Index\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sheet(dataframe):\n",
    "    adj=dataframe.dropna(axis=1,how='all')\n",
    "    adj=dataframe.set_index(adj.columns[0]) #use stock tickers as the index\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1483,
   "metadata": {},
   "outputs": [],
   "source": [
    "US=clean_sheet(pd.read_excel(r'C:\\Users\\Eric.Li\\Documents\\Center Book\\Raw US data.xlsx',\\\n",
    "                                       sheet_name='US'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SQL_price(region,start,end):\n",
    "    '''\n",
    "    Grab the pricing data from SQL database\n",
    "    region= US, Europe,Asia,or Canada\n",
    "    start,end are in year\n",
    "    key is the reference to search\n",
    "    return the target price dataframe with timestamp on the column\n",
    "    '''\n",
    "    mylist=[]\n",
    "    for year in range(start,end+1):\n",
    "        sql=\"select * from {0}_price_{1}\".format(region,year)\n",
    "        data=pd.read_sql(sql,cnxn).set_index(\"Ticker\")\n",
    "        adj_data=data.loc[[x for x in data.index if len(x)>0]].replace('#N/A N/A','')\n",
    "        mylist.append(adj_data)\n",
    "\n",
    "    price=pd.concat(mylist,axis=1)\n",
    "    price=price.apply(lambda x:pd.to_numeric(x),axis=1)\n",
    "    \n",
    "    sql_index=\"select * from {0}_price_index\".format(region)\n",
    "    data_index=pd.read_sql(sql_index,cnxn).set_index(\"Ticker\").T\n",
    "    data_index=data_index.replace('#N/A N/A','')\n",
    "    price_index=data_index.apply(lambda x:pd.to_numeric(x),axis=1)\n",
    "    \n",
    "    price.columns=[SQL_price_date_transform(i) for i in price.columns]\n",
    "    '''\n",
    "    Need to sort the columns for index price, and then transform to date string\n",
    "    '''\n",
    "    price_index.columns=[SQL_price_date_transform(i,index=True) for i in price_index.columns]\n",
    "    price_index=price_index.reindex(sorted(price_index.columns), axis=1)\n",
    "    price_index.columns=[i.strftime(\"%d/%b/%Y\") for i  in price_index.columns]\n",
    "    \n",
    "    abs_return=price.diff(1,axis=1)/price.shift(1,axis=1)\n",
    "    abs_return_index=price_index.diff(1,axis=1)/price_index.shift(1,axis=1)\n",
    "    return price,abs_return,price_index,abs_return_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SQL_price_date_transform(SQL_date,index=False):\n",
    "    '''\n",
    "    Transform the SQL price style string into dateframe string style\n",
    "    The SQL price follows US style which is MM DD YYYY\n",
    "    '''\n",
    "    if index==False:\n",
    "        timestamp=pd.Timestamp(int(SQL_date[SQL_date.find(\" \",3):]),\n",
    "                            int(SQL_date[:SQL_date.find(\" \")]),\n",
    "                            int(SQL_date[SQL_date.find(\" \",1):SQL_date.find(\" \",3)]))\n",
    "        return timestamp.strftime(\"%d/%b/%Y\")\n",
    "    else:\n",
    "        timestamp=pd.Timestamp(int(SQL_date[-4:]),int(SQL_date[3:5]),int(SQL_date[:2]))\n",
    "        return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Connect to post result SQL server'''\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=dsa-ln-WS015\\SQLEXPRESS;DATABASE=Post_result;Trusted_Connection=yes')   \n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Grab all the price data\n",
    "'''\n",
    "US_price,abs_return_US,US_index_price,abs_return_index_US=SQL_price('US',2006,2018)\n",
    "Asia_price,abs_return_Asia,Asia_index_price,abs_return_index_Asia=SQL_price('Asia',2007,2018)\n",
    "Europe_price,abs_return_Europe,Europe_index_price,abs_return_index_Europe=SQL_price('Europe',2006,2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aggregate all the sub price data and replace it with dataframe\n",
    "'''\n",
    "index_return=abs_return_index_US.append(abs_return_index_Asia).append(abs_return_index_Europe)\n",
    "index_return.columns=[datetime.strptime(x,\"%d/%b/%Y\") for x in index_return.columns]\n",
    "index_return=index_return.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import the daily pnl data from FI Val\n",
    "'''\n",
    "FI_VAL_daily=clean_sheet(pd.read_excel(r'C:\\Users\\Eric.Li\\Documents\\Center Book\\FI Val daily data.xlsx',sheet_name='Daily'))\n",
    "FI_VAL_daily[\"Signal\"]=list(zip(FI_VAL_daily[\"Ticker\"],FI_VAL_daily[\"Start\"]))\n",
    "FI_price=clean_sheet(pd.read_excel(r'C:\\Users\\Eric.Li\\Documents\\Center Book\\FI Val daily data.xlsx',sheet_name='Price'))\n",
    "abs_return=FI_price.T.diff()/FI_price.T.shift(1)\n",
    "abs_return=abs_return.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_date(overlapping_df,column_name):\n",
    "    '''\n",
    "    transform the dataframe with overlapping date index to a dataframe with unique date\n",
    "    '''\n",
    "    my_df=pd.DataFrame()\n",
    "    for i in sorted(set(overlapping_df.index.tolist())):\n",
    "        data_row=overlapping_df[overlapping_df.index==i][[column_name,'Signal']].T\n",
    "        data_row.columns=data_row.iloc[-1]\n",
    "        data_row=data_row.iloc[:-1]\n",
    "        data_row.index=[i]\n",
    "        my_df=pd.concat([my_df,data_row],axis=0)      \n",
    "    \n",
    "    return my_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Set the capital size\n",
    "'''\n",
    "capital=10**(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Update both pnl and size to unique date dataframe\n",
    "'''\n",
    "\n",
    "orig_FI_pnl=unique_date(FI_VAL_daily,'PNL')/capital\n",
    "orig_FI_size=unique_date(FI_VAL_daily,'Exposure')/capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get rid of a position with holding period less than 5 days\n",
    "'''\n",
    "FI_count=orig_FI_pnl.copy()\n",
    "FI_count[pd.notnull(FI_count)]=1\n",
    "\n",
    "orig_FI_size=orig_FI_size.loc[:,FI_count.sum(axis=0)>5]\n",
    "orig_FI_pnl=orig_FI_pnl.loc[:,FI_count.sum(axis=0)>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add the country column and create the hedge  \n",
    "Calculate both size and pnl\n",
    "'''\n",
    "\n",
    "FI_country=orig_FI_size.apply(lambda x:index_mapping[x.name[0][-2:]] if x.name[0][-2:] in index_mapping.keys() else None,axis=0)\n",
    "adj_FI_size=orig_FI_size.T\n",
    "adj_FI_size[\"country\"]=FI_country\n",
    "adj_FI_size=adj_FI_size[pd.notnull(adj_FI_size[\"country\"])] #get rid of countries that are not in the mapping\n",
    "alpha_FI_size=adj_FI_size.T.iloc[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_analytics_dollar(dollar_pnl_df,capital):\n",
    "    '''\n",
    "    dollar_pnl_df and capital\n",
    "    '''\n",
    "    \n",
    "    ind_return=dollar_pnl_df.sum(axis=0)/capital\n",
    "    signal_count=len(ind_return)\n",
    "    account_curve=dollar_pnl_df.sum(axis=1).cumsum()/capital\n",
    "    account_price=1+account_curve\n",
    "    \n",
    "    if signal_count==0:\n",
    "        return None,None,None,None,None,None,None\n",
    "    else:\n",
    "        mean_return=ind_return.mean()\n",
    "        hit_rate=len(ind_return[ind_return>0])/len(ind_return)*1.0\n",
    "        payoff_ratio=ind_return[ind_return>0].mean()/ind_return[ind_return<0].mean()*-1.0\n",
    "        \n",
    "        account_price=account_curve+1\n",
    "        ann_vol=np.std(account_price.diff()/account_price.shift(1))*(260**0.5)\n",
    "        ann_ret=(account_price.iloc[-1]**(1/len(account_price)))**260-1\n",
    "        ann_sharpe=ann_ret/ann_vol\n",
    "        \n",
    "        max_dd=-((1+account_curve)/(1+account_curve).cummax(axis=0)-1).expanding().min().min()\n",
    "        \n",
    "        #low_date=(np.maximum.accumulate(account_curve)-account_curve).idxmax()\n",
    "        #high_date=account_curve[:low_date].idxmax()\n",
    "        #max_dd=1-(1+account_curve[low_date])/(1+account_curve[high_date])\n",
    "        \n",
    "        return signal_count,hit_rate,payoff_ratio,ann_ret,ann_vol,ann_sharpe,max_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_analytics(daily_pnl_df):\n",
    "    '''\n",
    "    Key portfolio metrics from portfolio cache\n",
    "    Feed into plot function\n",
    "    '''\n",
    "    \n",
    "    ind_return=daily_pnl_df.sum(axis=0)\n",
    "    signal_count=len(ind_return)\n",
    "    account_curve=daily_pnl_df.cumsum().ffill().sum(axis=1)\n",
    "    \n",
    "    if signal_count==0:\n",
    "        return None,None,None,None,None,None,None\n",
    "    else:\n",
    "        mean_return=ind_return.mean()\n",
    "        hit_rate=len(ind_return[ind_return>0])/len(ind_return)*1.0\n",
    "        payoff_ratio=ind_return[ind_return>0].mean()/ind_return[ind_return<0].mean()*-1.0\n",
    "        \n",
    "        account_price=account_curve+1\n",
    "        ann_vol=np.std(account_price.diff()/account_price.shift(1))*(260**0.5)\n",
    "        ann_ret=(account_price.iloc[-1]**(1/len(account_price)))**260-1\n",
    "        ann_sharpe=ann_ret/ann_vol\n",
    "        \n",
    "        max_dd=-((1+account_curve)/(1+account_curve).cummax(axis=0)-1).expanding().min().min()\n",
    "        \n",
    "        #low_date=(np.maximum.accumulate(account_curve)-account_curve).idxmax()\n",
    "        #high_date=account_curve[:low_date].idxmax()\n",
    "        #max_dd=1-(1+account_curve[low_date])/(1+account_curve[high_date])\n",
    "        \n",
    "        return signal_count,hit_rate,payoff_ratio,ann_ret,ann_vol,ann_sharpe,max_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_account(return_df,index_return_df,orig_alpha_size,sizing,new_size):\n",
    "    \n",
    "    '''\n",
    "    Build signal account from original size dataframe, and apply to different sizing scheme\n",
    "    Sizing:\n",
    "    - original\n",
    "    - entry\n",
    "    - average\n",
    "    - equal\n",
    "    - risk parity\n",
    "    '''\n",
    "    \n",
    "    alpha_count_df=orig_alpha_size.copy()\n",
    "    alpha_count_df[pd.notnull(alpha_count_df)]=1\n",
    "        \n",
    "    alpha_return_df=return_df[[x[0] for x in alpha_count_df.columns]].loc[alpha_count_df.index]\n",
    "    alpha_return_df.columns=orig_alpha_size.columns\n",
    "    alpha_signal_df=alpha_return_df*alpha_count_df\n",
    "    \n",
    "    if sizing==\"original\":\n",
    "        alpha_size_df=orig_alpha_size\n",
    "    else:\n",
    "        if sizing==\"entry\":\n",
    "            size_row=orig_alpha_size.apply(lambda x: x.dropna().iloc[0],axis=0)\n",
    "        elif sizing==\"average\":\n",
    "            size_row=orig_alpha_size.mean(axis=0)\n",
    "        elif sizing==\"equal\":\n",
    "            size_row=orig_alpha_size.apply(lambda x:new_size if x.mean()>0 else -new_size,axis=0)\n",
    "        elif sizing==\"risk parity\":\n",
    "            vol_row=orig_alpha_size.apply(lambda x:return_df[x.name[0]].loc[:x.name[1]][-30:].std(),axis=0)\n",
    "            size_row=(vol_row.mean()/vol_row).fillna(1.0)*orig_alpha_size.apply(lambda x:new_size \\\n",
    "                                                                                if x.mean()>0 else -new_size,axis=0)\n",
    "        \n",
    "        alpha_size_df=(1+alpha_signal_df).cumprod()*size_row\n",
    "    \n",
    "    index_series=alpha_size_df.apply(lambda x:index_mapping[x.name[0][-2:]],axis=0)\n",
    "    adj_alpha_size_df=alpha_size_df.T\n",
    "    adj_alpha_size_df[\"Index\"]=index_series\n",
    "    \n",
    "    alpha_size_df=adj_alpha_size_df.T.iloc[:-1]\n",
    "    index_size_df=(adj_alpha_size_df.groupby(\"Index\").apply(sum)*-1).T.iloc[:-1]\n",
    "    index_signal_df=index_return_df[list(set(index_series.dropna()))].loc[alpha_signal_df.index]\n",
    "    \n",
    "    total_signal_df=pd.concat([alpha_signal_df,index_signal_df],axis=1)\n",
    "    total_size_df=pd.concat([alpha_size_df,index_size_df],axis=1)\n",
    "    \n",
    "    total_daily_pnl=total_size_df.shift(1)*total_signal_df\n",
    "    account_cuve=total_daily_pnl.cumsum().ffill().sum(axis=1)\n",
    "    \n",
    "    return total_daily_pnl,account_cuve,total_size_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_account(return_df,index_return_df,size_row,orig_size_df):\n",
    "    \n",
    "    alpha_count_df=orig_size_df.copy()\n",
    "    alpha_count_df[pd.notnull(alpha_count_df)]=1\n",
    "    \n",
    "    alpha_return_df=return_df[[x[0] for x in alpha_count_df.columns]].loc[alpha_count_df.index]\n",
    "    alpha_return_df.columns=orig_size_df.columns\n",
    "    alpha_signal_df=alpha_return_df*alpha_count_df\n",
    "    \n",
    "    alpha_size_df=(1+alpha_signal_df).cumprod()*(size_row*alpha_count_df)\n",
    "    \n",
    "    index_series=alpha_size_df.apply(lambda x:index_mapping[x.name[0][-2:]],axis=0)\n",
    "    adj_alpha_size_df=alpha_size_df.T\n",
    "    adj_alpha_size_df[\"Index\"]=index_series\n",
    "    \n",
    "    alpha_size_df=adj_alpha_size_df.T.iloc[:-1]\n",
    "    index_size_df=(adj_alpha_size_df.groupby(\"Index\").apply(sum)*-1).T.iloc[:-1]\n",
    "    index_signal_df=index_return_df[list(set(index_series.dropna()))].loc[alpha_signal_df.index]\n",
    "    \n",
    "    total_signal_df=pd.concat([alpha_signal_df,index_signal_df],axis=1)\n",
    "    total_size_df=pd.concat([alpha_size_df,index_size_df],axis=1)\n",
    "    \n",
    "    total_daily_pnl=total_size_df.shift(1)*total_signal_df\n",
    "    account_cuve=total_daily_pnl.cumsum().ffill().sum(axis=1)\n",
    "    \n",
    "    return total_daily_pnl,account_cuve,total_size_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5752: RuntimeWarning: '<' not supported between instances of 'str' and 'tuple', sort order is undefined for incomparable objects\n",
      "  other.columns, how=join, level=level, return_indexers=True)\n"
     ]
    }
   ],
   "source": [
    "daily_pnl,account_curve,size_df=signal_account(abs_return,index_return,alpha_FI_size,'equal',0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_FI_size=alpha_FI_size.loc[:,alpha_FI_size.apply(lambda x:x.mean(),axis=0)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_FI_size=alpha_FI_size.loc[:,alpha_FI_size.apply(lambda x:x.mean(),axis=0)<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5752: RuntimeWarning: '<' not supported between instances of 'str' and 'tuple', sort order is undefined for incomparable objects\n",
      "  other.columns, how=join, level=level, return_indexers=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(297,\n",
       " 0.4444444444444444,\n",
       " 2.021305039681683,\n",
       " 0.033439286708573324,\n",
       " 0.03331093025204848,\n",
       " 1.0038532834584213,\n",
       " 0.04064724174324996)"
      ]
     },
     "execution_count": 1363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_analytics(signal_account(abs_return,index_return,long_FI_size,'original',0.015)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5752: RuntimeWarning: '<' not supported between instances of 'str' and 'tuple', sort order is undefined for incomparable objects\n",
      "  other.columns, how=join, level=level, return_indexers=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(342,\n",
       " 0.4152046783625731,\n",
       " 1.5189555586142518,\n",
       " 0.004654187723273084,\n",
       " 0.021170467598921265,\n",
       " 0.21984340693118357,\n",
       " 0.038968761696676624)"
      ]
     },
     "execution_count": 1364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_analytics(signal_account(abs_return,index_return,short_FI_size,'original',0.015)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5752: RuntimeWarning: '<' not supported between instances of 'str' and 'tuple', sort order is undefined for incomparable objects\n",
      "  other.columns, how=join, level=level, return_indexers=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Entry sizing \n",
    "'''\n",
    "entry_FI_size_row=alpha_FI_size.apply(lambda x: x.dropna().iloc[0],axis=0)\n",
    "daily_pnl,account_curve=signal_account(abs_return,index_return,entry_FI_size_row/1000000000,alpha_FI_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartile_name(target_series,large):\n",
    "    '''\n",
    "    Input input data: target_series to run quartile analysis, large ranks higher if true\n",
    "    Output: pandas series that contains the quartile score\n",
    "    '''\n",
    "    quartile_series=target_series.copy()\n",
    "    if large:\n",
    "        quartile_series[target_series>target_series.quantile(0.8)]=1\n",
    "        quartile_series[(target_series>target_series.quantile(0.6))&(target_series<=target_series.quantile(0.8))]=2\n",
    "        quartile_series[(target_series>target_series.quantile(0.4))&(target_series<=target_series.quantile(0.6))]=3\n",
    "        quartile_series[(target_series>target_series.quantile(0.2))&(target_series<=target_series.quantile(0.4))]=4\n",
    "        quartile_series[target_series<=target_series.quantile(0.2)]=5\n",
    "    else:\n",
    "        quartile_series[target_series>target_series.quantile(0.8)]=5\n",
    "        quartile_series[(target_series>target_series.quantile(0.6))&(target_series<=target_series.quantile(0.8))]=4\n",
    "        quartile_series[(target_series>target_series.quantile(0.4))&(target_series<=target_series.quantile(0.6))]=3\n",
    "        quartile_series[(target_series>target_series.quantile(0.2))&(target_series<=target_series.quantile(0.4))]=2\n",
    "        quartile_series[target_series<=target_series.quantile(0.2)]=1\n",
    "    return quartile_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_rank_transform(fundamental_df):\n",
    "    '''\n",
    "    three factor version\n",
    "    '''\n",
    "    fundamental_df.loc[:,\"mom\"]=fundamental_df.apply(lambda x:x[\"RECENT PRICE\"]/x[\"BEFORE PRICE\"]-1 \\\n",
    "                                                     if type(x[\"BEFORE PRICE\"])==float \\\n",
    "             and type(x[\"RECENT PRICE\"])==float else None, axis=1)\n",
    "    \n",
    "    fundamental_df.loc[:,\"value\"]=fundamental_df.apply(lambda x:x[\"BOOK\"]/x[\"Market Cap\"] if type(x[\"BOOK\"])==int \\\n",
    "             and type(x[\"Market Cap\"])==int else None, axis=1)\n",
    "    \n",
    "    fundamental_df.loc[:,\"size\"]=fundamental_df.apply(lambda x: x[\"Market Cap\"] if type(x[\"Market Cap\"])==int else None, axis=1)\n",
    "    \n",
    "    fundamental_df=fundamental_df[np.isfinite(fundamental_df[\"mom\"])]\n",
    "    fundamental_df=fundamental_df[np.isfinite(fundamental_df[\"value\"])]\n",
    "    fundamental_df=fundamental_df[np.isfinite(fundamental_df[\"size\"])]\n",
    "    \n",
    "    fundamental_df.loc[:,\"size_rank\"]=quartile_name(fundamental_df[\"size\"],False)\n",
    "    \n",
    "    size_mom=pd.Series()\n",
    "    for i in set(fundamental_df[\"size_rank\"]):\n",
    "        target=fundamental_df[fundamental_df[\"size_rank\"]==i]\n",
    "        target[\"size_mom\"]=list(zip(target[\"size_rank\"],quartile_name(target[\"mom\"],True)))\n",
    "        size_mom=size_mom.append(target[\"size_mom\"])\n",
    "    \n",
    "    fundamental_df.loc[:,\"size_mom\"]=size_mom\n",
    "    \n",
    "    size_mom_value=[]\n",
    "    for i in set(fundamental_df[\"size_mom\"]):\n",
    "        target=fundamental_df[fundamental_df[\"size_mom\"]==i]\n",
    "        target[\"size_mom_value\"]=list(zip(list(zip(*target[\"size_mom\"]))[0],list(zip(*target[\"size_mom\"]))[1],\\\n",
    "                                          quartile_name(target[\"value\"],True)))\n",
    "        size_mom_value.append(target[\"size_mom_value\"])\n",
    "    \n",
    "    \n",
    "    fundamental_df.loc[:,\"size_mom_value\"]=pd.concat(size_mom_value,axis=0)\n",
    "    \n",
    "    return fundamental_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rank_dict=[]\n",
    "\n",
    "for i in list(set(US[\"Date\"]))[:3]:\n",
    "    target_US=US[US[\"Date\"]==i]\n",
    "    rank_dict.append(factor_rank_transform(target_US)[\"size_mom_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "1624579D US Equity    (2, 2.0, 5.0)\n",
       "1667208D US Equity    (1, 4.0, 4.0)\n",
       "1694944D CN Equity    (5, 5.0, 3.0)\n",
       "9191919D US Equity    (3, 3.0, 2.0)\n",
       "9871234D US Equity    (4, 4.0, 1.0)\n",
       "9999955D US Equity    (4, 4.0, 3.0)\n",
       "9999966D US Equity    (4, 5.0, 4.0)\n",
       "AA US Equity          (4, 1.0, 1.0)\n",
       "AAAP US Equity        (3, 2.0, 5.0)\n",
       "AAGIY US Equity       (5, 3.0, 3.0)\n",
       "AAL US Equity         (5, 2.0, 4.0)\n",
       "AAN US Equity         (3, 1.0, 1.0)\n",
       "AAOI US Equity        (1, 1.0, 3.0)\n",
       "AAON US Equity        (2, 3.0, 5.0)\n",
       "AAP US Equity         (4, 5.0, 3.0)\n",
       "AAPL US Equity        (5, 1.0, 4.0)\n",
       "AAV CN Equity         (2, 4.0, 1.0)\n",
       "AAWW US Equity        (2, 1.0, 1.0)\n",
       "AAXN US Equity        (1, 4.0, 5.0)\n",
       "ABAX US Equity        (1, 4.0, 4.0)\n",
       "ABB US Equity         (5, 4.0, 4.0)\n",
       "ABBV US Equity        (5, 3.0, 5.0)\n",
       "ABC US Equity         (5, 5.0, 5.0)\n",
       "ABCB US Equity        (2, 2.0, 3.0)\n",
       "ABCO US Equity        (2, 2.0, 4.0)\n",
       "ABEO US Equity        (1, 1.0, 4.0)\n",
       "ABEV US Equity        (5, 4.0, 3.0)\n",
       "ABG US Equity         (1, 3.0, 4.0)\n",
       "ABM US Equity         (3, 3.0, 3.0)\n",
       "ABMD US Equity        (4, 2.0, 5.0)\n",
       "                          ...      \n",
       "XLNX US Equity        (5, 3.0, 4.0)\n",
       "XLRN US Equity        (2, 2.0, 5.0)\n",
       "XNCR US Equity        (1, 3.0, 3.0)\n",
       "XOM US Equity         (5, 5.0, 2.0)\n",
       "XON US Equity         (2, 5.0, 5.0)\n",
       "XPER US Equity        (1, 4.0, 3.0)\n",
       "XPO US Equity         (4, 1.0, 2.0)\n",
       "XRAY US Equity        (4, 5.0, 2.0)\n",
       "XRX US Equity         (4, 2.0, 2.0)\n",
       "XYL US Equity         (4, 2.0, 3.0)\n",
       "Y US Equity           (4, 4.0, 1.0)\n",
       "YELP US Equity        (3, 3.0, 4.0)\n",
       "YNDX US Equity        (4, 1.0, 1.0)\n",
       "YPF US Equity         (4, 3.0, 1.0)\n",
       "YRD US Equity         (2, 1.0, 1.0)\n",
       "YRI CN Equity         (3, 5.0, 1.0)\n",
       "YUM US Equity         (5, 3.0, 5.0)\n",
       "YY US Equity          (3, 1.0, 1.0)\n",
       "Z US Equity           (4, 3.0, 3.0)\n",
       "ZAYO US Equity        (4, 3.0, 4.0)\n",
       "ZBH US Equity         (5, 5.0, 3.0)\n",
       "ZBRA US Equity        (4, 1.0, 4.0)\n",
       "ZEN US Equity         (3, 5.0, 5.0)\n",
       "ZG US Equity          (4, 3.0, 3.0)\n",
       "ZGNX US Equity        (1, 1.0, 4.0)\n",
       "ZION US Equity        (4, 1.0, 1.0)\n",
       "ZIOP US Equity        (1, 2.0, 5.0)\n",
       "ZNGA US Equity        (3, 1.0, 1.0)\n",
       "ZTS US Equity         (5, 2.0, 5.0)\n",
       "ZZZ CN Equity         (2, 3.0, 5.0)\n",
       "Name: size_mom_value, Length: 2297, dtype: object"
      ]
     },
     "execution_count": 1504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [],
   "source": [
    "US[\"size_rank\"]=quartile_name(US[\"size\"],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1433,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric.Li\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "size_mom=pd.Series()\n",
    "for i in range(1,6):\n",
    "    target=US[US[\"size_rank\"]==i]\n",
    "    target[\"size_mom\"]=list(zip(quartile_name(target[\"mom\"],True),target[\"size_rank\"]))\n",
    "    size_mom=size_mom.append(target[\"size_mom\"])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
